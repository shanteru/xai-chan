{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from utils import dataset_test, transform, bc_config, models\n",
    "from captum.attr import LayerGradCam, LRP\n",
    "import yaml\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(args_dict, fold, magnification):\n",
    "    \n",
    "    \n",
    "    encoder = args_dict[\"encoder\"][\"name\"]\n",
    "    version = args_dict[\"encoder\"][\"version\"]\n",
    "    dropout = args_dict[\"encoder\"][\"fc_dropout\"]\n",
    "    \n",
    "    downstream_task_model = None\n",
    "    if \"resnet\" == encoder:\n",
    "        downstream_task_model = models.ResNet_Model(version=int(version), pretrained=True)\n",
    "        num_ftrs = downstream_task_model.num_ftrs\n",
    "        downstream_task_model.model.fc = nn.Sequential(nn.Dropout(dropout), nn.Linear(num_ftrs, 1))\n",
    "    \n",
    "    downstream_task_model = downstream_task_model.to(device)\n",
    "    \n",
    "    # Load weights (You need to specify the path properly)\n",
    "    model_path = os.path.join(args_dict[\"results\"][\"result_base_path\"], f\"weights_{fold}_{magnification}.pth\")\n",
    "    downstream_task_model.load_state_dict(torch.load(model_path))\n",
    "    downstream_task_model.eval()\n",
    "    \n",
    "    return downstream_task_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    \"\"\"Load configuration information from a yaml file.\"\"\"\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradcam(model, dataloader, target_layer):\n",
    "    grad_cam = LayerGradCam(model, target_layer)\n",
    "    attributions = []\n",
    "    \n",
    "    for inputs, _ in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        attribution = grad_cam.attribute(inputs, target=1) # Assuming binary classification\n",
    "        attributions.append(attribution)\n",
    "    \n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = load_config(\"imagenet_run.yaml\")\n",
    "    \n",
    "    for fold in list(config[\"computational_infra\"][\"fold_to_gpu_mapping\"].keys()):\n",
    "        model = load_pretrained_model(config, fold, '400X')\n",
    "        \n",
    "        # Load your data (maybe validation data)\n",
    "        val_loader = dataset_test.get_breakhis_data_loader(\n",
    "        dataset_path=os.path.join(data_path, fold, 'test_20'),\n",
    "        transform=transform.resize_transform,\n",
    "        pre_processing=[],\n",
    "        image_type_list=['400X'],\n",
    "        num_workers=2,\n",
    "        is_test=True\n",
    "    )\n",
    "        \n",
    "        # Compute GradCAM attributions\n",
    "        target_layer = model.model.layer4  # You need to specify the target layer for GradCAM\n",
    "        gradcam_attributions = compute_gradcam(model, val_loader, target_layer)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
