{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/anaconda3/envs/xai-chan/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Faithfulness',\n",
       " 'Robustness',\n",
       " 'Localisation',\n",
       " 'Complexity',\n",
       " 'Randomisation',\n",
       " 'Axiomatic']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import quantus\n",
    "\n",
    "quantus.helpers.constants.available_categories()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Faithfulness': ['Faithfulness Correlation',\n",
       "  'Faithfulness Estimate',\n",
       "  'Pixel-Flipping',\n",
       "  'Region Segmentation',\n",
       "  'Monotonicity-Arya',\n",
       "  'Monotonicity-Nguyen',\n",
       "  'Selectivity',\n",
       "  'SensitivityN',\n",
       "  'IROF',\n",
       "  'ROAD',\n",
       "  'Infidelity',\n",
       "  'Sufficiency'],\n",
       " 'Robustness': ['Continuity Test',\n",
       "  'Local Lipschitz Estimate',\n",
       "  'Max-Sensitivity',\n",
       "  'Avg-Sensitivity',\n",
       "  'Consistency',\n",
       "  'Relative Input Stability',\n",
       "  'Relative Output Stability',\n",
       "  'Relative Representation Stability'],\n",
       " 'Localisation': ['Pointing Game',\n",
       "  'Top-K Intersection',\n",
       "  'Relevance Mass Accuracy',\n",
       "  'Relevance Rank Accuracy',\n",
       "  'Attribution Localisation ',\n",
       "  'AUC',\n",
       "  'Focus'],\n",
       " 'Complexity': ['Sparseness', 'Complexity', 'Effective Complexity'],\n",
       " 'Randomisation': ['Model Parameter Randomisation', 'Random Logit'],\n",
       " 'Axiomatic': ['Completeness', 'NonSensitivity', 'InputInvariance']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantus.helpers.constants.available_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet_Model(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.8, inplace=False)\n",
       "      (1): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.models import ResNet_Model\n",
    "import torch\n",
    "weights_path = \"/home/student/Desktop/31171109-donotdelete/xai-chan/result/imagenet/_Fold_2_5_400X_BreakHis_FT_60_resnet50_imagenet_/_37_96.07250755287009_95.06917631917632_0.9614846110343933.pth\"  # TODO: Provide the model path\n",
    "# def force_cudnn_initialization(device):\n",
    "#     s = 32\n",
    "#     torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=device), torch.zeros(s, s, s, s, device=device))\n",
    "device = torch.device('cuda:0')\n",
    "# force_cudnn_initialization(device=device)\n",
    "\n",
    "# Load model\n",
    "version = 50\n",
    "downstream_task_model = ResNet_Model(version=version).to(device)\n",
    "downstream_task_model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "downstream_task_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as t\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, benign_path, malignant_path, transform=None, augmentation=None):\n",
    "        # Store all the image paths and associated labels (0 for benign, 1 for malignant)\n",
    "        self.image_paths = [os.path.join(benign_path, fname) for fname in os.listdir(benign_path)] + \\\n",
    "                           [os.path.join(malignant_path, fname) for fname in os.listdir(malignant_path)]\n",
    "        self.labels = [0] * len(os.listdir(benign_path)) + [1] * len(os.listdir(malignant_path))\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image\n",
    "        img = PIL.Image.open(img_path)\n",
    "\n",
    "        # Convert image to numpy array\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.augmentation:\n",
    "            augmented = self.augmentation(image=img_np)\n",
    "            img_np = augmented[\"image\"]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img_np)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Replace with your image paths\n",
    "\n",
    "BENIGN_PATH = \"/home/student/Desktop/31171109-donotdelete/xai-chan/explanation/val_10/SOB_B_F_14-21998EF/400X\"\n",
    "MALIGNANT_PATH = \"/home/student/Desktop/31171109-donotdelete/xai-chan/explanation/val_10/SOB_M_LC_14-16196/400X\"\n",
    "\n",
    "# Define transformations\n",
    "transform = t.Compose([\n",
    "    t.ToPILImage(), \n",
    "    t.Resize((341, 341)),\n",
    "    t.ToTensor()\n",
    "])\n",
    "\n",
    "augmentation_03 = A.Compose([\n",
    "    A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, always_apply=False, p=0.3),\n",
    "    A.Flip(p=0.3),\n",
    "    A.Rotate(p=0.3),\n",
    "    A.Affine(translate_percent=0.05, p=0.3),\n",
    "    A.Resize(height=341, width=341, p=1),\n",
    "    A.RandomCrop(height=252, width=252, p=1),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "dataset = CustomDataset(BENIGN_PATH, MALIGNANT_PATH, transform=transform, augmentation=augmentation_03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.9961, 0.9961, 0.9961,  ..., 0.9020, 0.9098, 0.9098],\n",
      "          [0.9882, 0.9922, 0.9922,  ..., 0.8902, 0.9020, 0.9137],\n",
      "          [0.9725, 0.9765, 0.9843,  ..., 0.8863, 0.8980, 0.9137],\n",
      "          ...,\n",
      "          [0.8157, 0.8588, 0.8980,  ..., 0.9529, 0.9216, 0.8980],\n",
      "          [0.8196, 0.8588, 0.8863,  ..., 0.9490, 0.9216, 0.9020],\n",
      "          [0.8078, 0.8392, 0.8588,  ..., 0.9490, 0.9216, 0.8980]],\n",
      "\n",
      "         [[0.8745, 0.8824, 0.8863,  ..., 0.8039, 0.8039, 0.8000],\n",
      "          [0.8353, 0.8431, 0.8471,  ..., 0.7922, 0.7961, 0.8039],\n",
      "          [0.7804, 0.7843, 0.7882,  ..., 0.7882, 0.8000, 0.8157],\n",
      "          ...,\n",
      "          [0.3098, 0.3529, 0.3922,  ..., 0.5608, 0.5059, 0.4627],\n",
      "          [0.3255, 0.3529, 0.3804,  ..., 0.5608, 0.5137, 0.4784],\n",
      "          [0.3176, 0.3373, 0.3529,  ..., 0.5647, 0.5216, 0.4863]],\n",
      "\n",
      "         [[0.9569, 0.9608, 0.9608,  ..., 0.9020, 0.9020, 0.8941],\n",
      "          [0.9451, 0.9529, 0.9569,  ..., 0.8863, 0.8980, 0.9020],\n",
      "          [0.9255, 0.9373, 0.9412,  ..., 0.8824, 0.8980, 0.9137],\n",
      "          ...,\n",
      "          [0.7451, 0.7725, 0.7922,  ..., 0.8588, 0.8275, 0.7961],\n",
      "          [0.7451, 0.7686, 0.7804,  ..., 0.8510, 0.8275, 0.8000],\n",
      "          [0.7333, 0.7490, 0.7490,  ..., 0.8510, 0.8235, 0.7961]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.8824, 0.8824, 0.8745],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.8667, 0.8745, 0.8784],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.8549, 0.8667, 0.8745],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.8745, 0.8549, 0.8353],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.8667, 0.8510, 0.8353],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.8588, 0.8353, 0.8275]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.6431, 0.6431, 0.6275],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.6275, 0.6353, 0.6314],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.6118, 0.6235, 0.6314],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.6078, 0.5882, 0.5686],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.6000, 0.5804, 0.5686],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.5843, 0.5608, 0.5529]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.7647, 0.7608, 0.7490],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7529, 0.7529, 0.7529],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7451, 0.7490, 0.7529],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7922, 0.7804, 0.7686],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7882, 0.7804, 0.7686],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7804, 0.7647, 0.7569]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.7176, 0.7137, 0.7137],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7216, 0.7216, 0.7216],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7255, 0.7373, 0.7373],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.9451, 0.9373, 0.9373],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.9412, 0.9255, 0.9137],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.9451, 0.9216, 0.8902]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.4941, 0.4941, 0.4941],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.4980, 0.4980, 0.4902],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.5098, 0.5098, 0.5020],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7373, 0.7255, 0.7216],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7216, 0.7059, 0.6941],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7098, 0.6902, 0.6627]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.6902, 0.6863, 0.6902],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.6902, 0.6902, 0.6980],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.6941, 0.7059, 0.7137],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.8078, 0.8000, 0.8078],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.8078, 0.7922, 0.7882],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.8078, 0.7843, 0.7647]]],\n",
      "\n",
      "\n",
      "        [[[0.9804, 0.9882, 0.9843,  ..., 0.8353, 0.8627, 0.8941],\n",
      "          [0.9882, 0.9961, 0.9922,  ..., 0.8039, 0.8275, 0.8588],\n",
      "          [0.9961, 1.0000, 0.9961,  ..., 0.7843, 0.8039, 0.8275],\n",
      "          ...,\n",
      "          [0.8588, 0.8706, 0.9137,  ..., 0.9725, 0.9569, 0.9569],\n",
      "          [0.8980, 0.8980, 0.9255,  ..., 0.9569, 0.9333, 0.9412],\n",
      "          [0.9451, 0.9294, 0.9373,  ..., 0.9373, 0.9137, 0.9216]],\n",
      "\n",
      "         [[0.5882, 0.6118, 0.6000,  ..., 0.3922, 0.4118, 0.4392],\n",
      "          [0.6157, 0.6392, 0.6353,  ..., 0.3686, 0.3882, 0.4118],\n",
      "          [0.6392, 0.6588, 0.6627,  ..., 0.3569, 0.3725, 0.3843],\n",
      "          ...,\n",
      "          [0.4549, 0.4745, 0.5373,  ..., 0.6353, 0.5882, 0.5686],\n",
      "          [0.5020, 0.5059, 0.5451,  ..., 0.6039, 0.5529, 0.5412],\n",
      "          [0.5490, 0.5373, 0.5529,  ..., 0.5686, 0.5216, 0.5137]],\n",
      "\n",
      "         [[0.8510, 0.8667, 0.8392,  ..., 0.6431, 0.6667, 0.6941],\n",
      "          [0.8627, 0.8824, 0.8667,  ..., 0.6157, 0.6392, 0.6667],\n",
      "          [0.8667, 0.8902, 0.8941,  ..., 0.6000, 0.6157, 0.6392],\n",
      "          ...,\n",
      "          [0.6941, 0.7020, 0.7451,  ..., 0.8000, 0.7686, 0.7569],\n",
      "          [0.7255, 0.7216, 0.7529,  ..., 0.7765, 0.7412, 0.7373],\n",
      "          [0.7647, 0.7490, 0.7608,  ..., 0.7529, 0.7216, 0.7216]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.9373, 0.9216, 0.9059],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.9333, 0.9176, 0.9020],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.9294, 0.9137, 0.8980],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.8353, 0.8549, 0.8627],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.8431, 0.8667, 0.8706],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.8588, 0.8824, 0.8784]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.7647, 0.7294, 0.6980],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7686, 0.7333, 0.6980],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7647, 0.7333, 0.6980],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.4745, 0.4863, 0.4863],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.4863, 0.4980, 0.4980],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.5020, 0.5137, 0.5059]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.7725, 0.7451, 0.7176],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7725, 0.7412, 0.7098],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.7686, 0.7412, 0.7059],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.5373, 0.5451, 0.5451],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.5490, 0.5608, 0.5569],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.5647, 0.5725, 0.5647]]]]) tensor([1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "SHUFFLE = False\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "\n",
    "# Example to get a batch of data\n",
    "for x_batch, y_batch in data_loader:\n",
    "    # x_batch contains images, y_batch contains labels\n",
    "    # Generate Integrated Gradients attributions of the first batch of the test set.\n",
    "\n",
    "    pass\n",
    "print(x_batch,y_batch)\n",
    "x_batch, y_batch = x_batch.to(device),  y_batch.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zennit\n",
    "# The canonizer can be a zennit.canonizers.Canonizer subclass or None.\n",
    "canonizer = None \n",
    "\n",
    "# The composite can be a zennit.core.Composite subclass, a string mapping to a composite, or None.\n",
    "composite = None\n",
    "\n",
    "# The attributor can be any zennit.attribution.Attributor subclass.\n",
    "attributor = zennit.attribution.IntegratedGradients \n",
    "\n",
    "# In case both captum and zennit are installed, this kwarg also needs to be set to \"zennit\"\n",
    "xai_lib = \"zennit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "# import os\n",
    "\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 15.88 GiB total capacity; 7.29 GiB already allocated; 42.00 MiB free; 7.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Generate Integrated Gradients attributions of the first batch of the test set.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m a_batch \u001b[39m=\u001b[39m quantus\u001b[39m.\u001b[39;49mexplain(\n\u001b[1;32m      3\u001b[0m     downstream_task_model, \n\u001b[1;32m      4\u001b[0m     x_batch, \n\u001b[1;32m      5\u001b[0m     y_batch, \n\u001b[1;32m      6\u001b[0m     canonizer\u001b[39m=\u001b[39;49mcanonizer,\n\u001b[1;32m      7\u001b[0m     composite\u001b[39m=\u001b[39;49mcomposite,\n\u001b[1;32m      8\u001b[0m     attributor\u001b[39m=\u001b[39;49mattributor,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[39m# Save x_batch and y_batch as numpy arrays that will be used to call metric instances.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m x_batch_tmp, y_batch_tmp \u001b[39m=\u001b[39m x_batch\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy(), y_batch\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/quantus/functions/explanation_func.py:126\u001b[0m, in \u001b[0;36mexplain\u001b[0;34m(model, inputs, targets, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m __EXTRAS__:\n\u001b[1;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExplanation library not found. Please install Captum or Zennit for torch>=1.2 models \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand tf-explain for TensorFlow>=2.0.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 126\u001b[0m explanation \u001b[39m=\u001b[39m get_explanation(model, inputs, targets, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    128\u001b[0m \u001b[39mreturn\u001b[39;00m explanation\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/quantus/functions/explanation_func.py:178\u001b[0m, in \u001b[0;36mget_explanation\u001b[0;34m(model, inputs, targets, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m util\u001b[39m.\u001b[39mfind_spec(\u001b[39m\"\u001b[39m\u001b[39mcaptum\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m util\u001b[39m.\u001b[39mfind_spec(\u001b[39m\"\u001b[39m\u001b[39mzennit\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    177\u001b[0m     \u001b[39mif\u001b[39;00m xai_lib \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcaptum\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[39mreturn\u001b[39;00m generate_captum_explanation(model, inputs, targets, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m xai_lib \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzennit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    180\u001b[0m         \u001b[39mreturn\u001b[39;00m generate_zennit_explanation(model, inputs, targets, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/quantus/functions/explanation_func.py:581\u001b[0m, in \u001b[0;36mgenerate_captum_explanation\u001b[0;34m(model, inputs, targets, device, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m     explanation \u001b[39m=\u001b[39m f_reduce_axes(\n\u001b[1;32m    576\u001b[0m         attr_func(model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mxai_lib_kwargs)\u001b[39m.\u001b[39mattribute(inputs\u001b[39m=\u001b[39minputs, target\u001b[39m=\u001b[39mtargets)\n\u001b[1;32m    577\u001b[0m     )\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGradient\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    580\u001b[0m     explanation \u001b[39m=\u001b[39m f_reduce_axes(\n\u001b[0;32m--> 581\u001b[0m         Saliency(model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mxai_lib_kwargs)\u001b[39m.\u001b[39;49mattribute(\n\u001b[1;32m    582\u001b[0m             inputs\u001b[39m=\u001b[39;49minputs, target\u001b[39m=\u001b[39;49mtargets, \u001b[39mabs\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    583\u001b[0m         )\n\u001b[1;32m    584\u001b[0m     )\n\u001b[1;32m    586\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOcclusion\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    587\u001b[0m     window_shape \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mwindow\u001b[39m\u001b[39m\"\u001b[39m, (\u001b[39m1\u001b[39m, \u001b[39m*\u001b[39m([\u001b[39m4\u001b[39m] \u001b[39m*\u001b[39m (inputs\u001b[39m.\u001b[39mndim \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m))))\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/captum/attr/_core/saliency.py:130\u001b[0m, in \u001b[0;36mSaliency.attribute\u001b[0;34m(self, inputs, target, abs, additional_forward_args)\u001b[0m\n\u001b[1;32m    126\u001b[0m gradient_mask \u001b[39m=\u001b[39m apply_gradient_requirements(inputs)\n\u001b[1;32m    128\u001b[0m \u001b[39m# No need to format additional_forward_args here.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m# They are being formated in the `_run_forward` function in `common.py`\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m gradients \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_func(\n\u001b[1;32m    131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_func, inputs, target, additional_forward_args\n\u001b[1;32m    132\u001b[0m )\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mabs\u001b[39m:\n\u001b[1;32m    134\u001b[0m     attributions \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(torch\u001b[39m.\u001b[39mabs(gradient) \u001b[39mfor\u001b[39;00m gradient \u001b[39min\u001b[39;00m gradients)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/captum/_utils/gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[39m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     outputs \u001b[39m=\u001b[39m _run_forward(forward_fn, inputs, target_ind, additional_forward_args)\n\u001b[1;32m    113\u001b[0m     \u001b[39massert\u001b[39;00m outputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTarget not provided when necessary, cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m take gradient with respect to multiple outputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[39m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/captum/_utils/common.py:482\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    479\u001b[0m inputs \u001b[39m=\u001b[39m _format_inputs(inputs)\n\u001b[1;32m    480\u001b[0m additional_forward_args \u001b[39m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[0;32m--> 482\u001b[0m output \u001b[39m=\u001b[39m forward_func(\n\u001b[1;32m    483\u001b[0m     \u001b[39m*\u001b[39;49m(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49madditional_forward_args)\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;49;00m additional_forward_args \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    485\u001b[0m     \u001b[39melse\u001b[39;49;00m inputs\n\u001b[1;32m    486\u001b[0m )\n\u001b[1;32m    487\u001b[0m \u001b[39mreturn\u001b[39;00m _select_targets(output, target)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/31171109-donotdelete/xai-chan/utils/models.py:60\u001b[0m, in \u001b[0;36mResNet_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_sigmoid_head:\n\u001b[0;32m---> 60\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msig(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x))\n\u001b[1;32m     61\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torchvision/models/resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[39m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    269\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 15.88 GiB total capacity; 7.29 GiB already allocated; 42.00 MiB free; 7.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Generate Integrated Gradients attributions of the first batch of the test set.\n",
    "a_batch = quantus.explain(\n",
    "    downstream_task_model, \n",
    "    x_batch, \n",
    "    y_batch, \n",
    "    canonizer=canonizer,\n",
    "    composite=composite,\n",
    "    attributor=attributor,\n",
    ")\n",
    "\n",
    "# Save x_batch and y_batch as numpy arrays that will be used to call metric instances.\n",
    "x_batch_tmp, y_batch_tmp = x_batch.cpu().numpy(), y_batch.cpu().numpy()\n",
    "\n",
    "# Quick assert.\n",
    "assert [isinstance(obj, np.ndarray) for obj in [x_batch, y_batch, a_batch]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_batch_tmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m# Plot examplary explanations!\u001b[39;00m\n\u001b[1;32m     20\u001b[0m fig, axes \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(nrows\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, ncols\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[0;32m---> 21\u001b[0m axes[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mimshow(np\u001b[39m.\u001b[39mmoveaxis(quantus\u001b[39m.\u001b[39mnormalise_func\u001b[39m.\u001b[39mdenormalise(x_batch_tmp[index], mean\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray([\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m]), std\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray([\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m])), \u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), vmin\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, vmax\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m)\n\u001b[1;32m     22\u001b[0m axes[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtitle\u001b[39m.\u001b[39mset_text(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mImageNet class \u001b[39m\u001b[39m{\u001b[39;00my_batch_tmp[index]\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m exp \u001b[39m=\u001b[39m axes[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mimshow(a_batch[index]\u001b[39m.\u001b[39mreshape(\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m), cmap\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mseismic\u001b[39m\u001b[39m\"\u001b[39m) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_batch_tmp' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqoAAAGyCAYAAAAs6OYBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAf1klEQVR4nO3db3CV5Zn48SsEc6JTE7EsCbCxVFtrWxUsSDZax3En28zo0OVFp6l2gGX8s7asY8nsVhAltbaEddVhpsYyUq19URdaR51OYeLabJmONTtMgczYFXQsWthOE2G7JmxsE0mefeHP+EsJeE4gyZ3j5zNzXuTxec65b4IXX87JOZRkWZYFAAAkZtpkLwAAAEYjVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASFLBofqLX/wilixZEnPmzImSkpJ45pln3veanTt3xmc+85nI5XLxsY99LB5//PExLBWgOJijAPkpOFT7+vpi/vz50dramtf5r732Wlx33XVxzTXXRGdnZ3zta1+Lm266KZ599tmCFwtQDMxRgPyUZFmWjfnikpJ4+umnY+nSpSc854477ojt27fHr3/96+FjX/rSl+LNN9+Mtra2sT40QFEwRwFObPp4P0BHR0fU19ePONbQ0BBf+9rXTnhNf39/9Pf3D389NDQUf/jDH+LDH/5wlJSUjNdSgQ+wLMvi6NGjMWfOnJg2La0f3zdHgalgPObouIdqV1dXVFVVjThWVVUVvb298cc//jHOPPPM465paWmJe+65Z7yXBnCcQ4cOxV/+5V9O9jJGMEeBqeR0ztFxD9WxWLt2bTQ1NQ1/3dPTE+edd14cOnQoKioqJnFlQLHq7e2NmpqaOPvssyd7KaeFOQpMtPGYo+MeqtXV1dHd3T3iWHd3d1RUVIz6LEBERC6Xi1wud9zxiooKAxYYVym+LG6OAlPJ6Zyj4/6DWHV1ddHe3j7i2HPPPRd1dXXj/dAARcEcBT6oCg7V//3f/43Ozs7o7OyMiHc+NqWzszMOHjwYEe+83LR8+fLh82+99dY4cOBAfP3rX4/9+/fHww8/HD/60Y9i9erVp2cHAFOMOQqQn4JD9Ve/+lVcdtllcdlll0VERFNTU1x22WWxfv36iIj4/e9/PzxsIyI++tGPxvbt2+O5556L+fPnxwMPPBDf+973oqGh4TRtAWBqMUcB8nNKn6M6UXp7e6OysjJ6enr8bBUwLop9zhT7/oDJNx5zJq0PCwQAgP9HqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkCShCgBAkoQqAABJEqoAACRJqAIAkKQxhWpra2vMmzcvysvLo7a2Nnbt2nXS8zdt2hSf+MQn4swzz4yamppYvXp1/OlPfxrTggGKgTkK8P4KDtVt27ZFU1NTNDc3x549e2L+/PnR0NAQb7zxxqjnP/HEE7FmzZpobm6Offv2xaOPPhrbtm2LO++885QXDzAVmaMA+Sk4VB988MG4+eabY+XKlfGpT30qNm/eHGeddVY89thjo57/wgsvxJVXXhk33HBDzJs3Lz73uc/F9ddf/77PHgAUK3MUID8FherAwEDs3r076uvr37uDadOivr4+Ojo6Rr3miiuuiN27dw8P1AMHDsSOHTvi2muvPeHj9Pf3R29v74gbQDEwRwHyN72Qk48cORKDg4NRVVU14nhVVVXs379/1GtuuOGGOHLkSHz2s5+NLMvi2LFjceutt570JauWlpa45557ClkawJRgjgLkb9zf9b9z587YsGFDPPzww7Fnz5546qmnYvv27XHvvfee8Jq1a9dGT0/P8O3QoUPjvUyAZJmjwAdVQc+ozpw5M0pLS6O7u3vE8e7u7qiurh71mrvvvjuWLVsWN910U0REXHLJJdHX1xe33HJLrFu3LqZNO76Vc7lc5HK5QpYGMCWYowD5K+gZ1bKysli4cGG0t7cPHxsaGor29vaoq6sb9Zq33nrruCFaWloaERFZlhW6XoApzRwFyF9Bz6hGRDQ1NcWKFSti0aJFsXjx4ti0aVP09fXFypUrIyJi+fLlMXfu3GhpaYmIiCVLlsSDDz4Yl112WdTW1sarr74ad999dyxZsmR40AJ8kJijAPkpOFQbGxvj8OHDsX79+ujq6ooFCxZEW1vb8BsDDh48OOJv/nfddVeUlJTEXXfdFb/73e/iL/7iL2LJkiXx7W9/+/TtAmAKMUcB8lOSTYHXjXp7e6OysjJ6enqioqJispcDFKFinzPFvj9g8o3HnBn3d/0DAMBYCFUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJI0plBtbW2NefPmRXl5edTW1sauXbtOev6bb74Zq1atitmzZ0cul4sLL7wwduzYMaYFAxQDcxTg/U0v9IJt27ZFU1NTbN68OWpra2PTpk3R0NAQL7/8csyaNeu48wcGBuJv/uZvYtasWfHkk0/G3Llz47e//W2cc845p2P9AFOOOQqQn5Isy7JCLqitrY3LL788HnrooYiIGBoaipqamrjttttizZo1x52/efPm+Jd/+ZfYv39/nHHGGWNaZG9vb1RWVkZPT09UVFSM6T4ATmYi54w5ChSj8ZgzBb30PzAwELt37476+vr37mDatKivr4+Ojo5Rr/nJT34SdXV1sWrVqqiqqoqLL744NmzYEIODgyd8nP7+/ujt7R1xAygG5ihA/goK1SNHjsTg4GBUVVWNOF5VVRVdXV2jXnPgwIF48sknY3BwMHbs2BF33313PPDAA/Gtb33rhI/T0tISlZWVw7eamppClgmQLHMUIH/j/q7/oaGhmDVrVjzyyCOxcOHCaGxsjHXr1sXmzZtPeM3atWujp6dn+Hbo0KHxXiZAssxR4IOqoDdTzZw5M0pLS6O7u3vE8e7u7qiurh71mtmzZ8cZZ5wRpaWlw8c++clPRldXVwwMDERZWdlx1+RyucjlcoUsDWBKMEcB8lfQM6plZWWxcOHCaG9vHz42NDQU7e3tUVdXN+o1V155Zbz66qsxNDQ0fOyVV16J2bNnjzpcAYqZOQqQv4Jf+m9qaootW7bED37wg9i3b1985Stfib6+vli5cmVERCxfvjzWrl07fP5XvvKV+MMf/hC33357vPLKK7F9+/bYsGFDrFq16vTtAmAKMUcB8lPw56g2NjbG4cOHY/369dHV1RULFiyItra24TcGHDx4MKZNe69/a2pq4tlnn43Vq1fHpZdeGnPnzo3bb7897rjjjtO3C4ApxBwFyE/Bn6M6GXz+HzDein3OFPv+gMk36Z+jCgAAE0WoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQpDGFamtra8ybNy/Ky8ujtrY2du3aldd1W7dujZKSkli6dOlYHhagaJijAO+v4FDdtm1bNDU1RXNzc+zZsyfmz58fDQ0N8cYbb5z0utdffz3+8R//Ma666qoxLxagGJijAPkpOFQffPDBuPnmm2PlypXxqU99KjZv3hxnnXVWPPbYYye8ZnBwML785S/HPffcE+eff/4pLRhgqjNHAfJTUKgODAzE7t27o76+/r07mDYt6uvro6Oj44TXffOb34xZs2bFjTfemNfj9Pf3R29v74gbQDEwRwHyV1CoHjlyJAYHB6OqqmrE8aqqqujq6hr1mueffz4effTR2LJlS96P09LSEpWVlcO3mpqaQpYJkCxzFCB/4/qu/6NHj8ayZctiy5YtMXPmzLyvW7t2bfT09AzfDh06NI6rBEiXOQp8kE0v5OSZM2dGaWlpdHd3jzje3d0d1dXVx53/m9/8Jl5//fVYsmTJ8LGhoaF3Hnj69Hj55ZfjggsuOO66XC4XuVyukKUBTAnmKED+CnpGtaysLBYuXBjt7e3Dx4aGhqK9vT3q6uqOO/+iiy6KF198MTo7O4dvn//85+Oaa66Jzs5OL0UBHzjmKED+CnpGNSKiqakpVqxYEYsWLYrFixfHpk2boq+vL1auXBkREcuXL4+5c+dGS0tLlJeXx8UXXzzi+nPOOSci4rjjAB8U5ihAfgoO1cbGxjh8+HCsX78+urq6YsGCBdHW1jb8xoCDBw/GtGn+wSuAEzFHAfJTkmVZNtmLeD+9vb1RWVkZPT09UVFRMdnLAYpQsc+ZYt8fMPnGY874KzsAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJGlModra2hrz5s2L8vLyqK2tjV27dp3w3C1btsRVV10VM2bMiBkzZkR9ff1Jzwf4IDBHAd5fwaG6bdu2aGpqiubm5tizZ0/Mnz8/Ghoa4o033hj1/J07d8b1118fP//5z6OjoyNqamric5/7XPzud7875cUDTEXmKEB+SrIsywq5oLa2Ni6//PJ46KGHIiJiaGgoampq4rbbbos1a9a87/WDg4MxY8aMeOihh2L58uV5PWZvb29UVlZGT09PVFRUFLJcgLxM5JwxR4FiNB5zpqBnVAcGBmL37t1RX1//3h1Mmxb19fXR0dGR13289dZb8fbbb8e55557wnP6+/ujt7d3xA2gGJijAPkrKFSPHDkSg4ODUVVVNeJ4VVVVdHV15XUfd9xxR8yZM2fEkP5zLS0tUVlZOXyrqakpZJkAyTJHAfI3oe/637hxY2zdujWefvrpKC8vP+F5a9eujZ6enuHboUOHJnCVAOkyR4EPkumFnDxz5swoLS2N7u7uEce7u7ujurr6pNfef//9sXHjxvjZz34Wl1566UnPzeVykcvlClkawJRgjgLkr6BnVMvKymLhwoXR3t4+fGxoaCja29ujrq7uhNfdd999ce+990ZbW1ssWrRo7KsFmOLMUYD8FfSMakREU1NTrFixIhYtWhSLFy+OTZs2RV9fX6xcuTIiIpYvXx5z586NlpaWiIj453/+51i/fn088cQTMW/evOGfwfrQhz4UH/rQh07jVgCmBnMUID8Fh2pjY2McPnw41q9fH11dXbFgwYJoa2sbfmPAwYMHY9q0956o/e53vxsDAwPxhS98YcT9NDc3xze+8Y1TWz3AFGSOAuSn4M9RnQw+/w8Yb8U+Z4p9f8Dkm/TPUQUAgIkiVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASJJQBQAgSUIVAIAkCVUAAJIkVAEASNKYQrW1tTXmzZsX5eXlUVtbG7t27Trp+T/+8Y/joosuivLy8rjkkktix44dY1osQLEwRwHeX8Ghum3btmhqaorm5ubYs2dPzJ8/PxoaGuKNN94Y9fwXXnghrr/++rjxxhtj7969sXTp0li6dGn8+te/PuXFA0xF5ihAfkqyLMsKuaC2tjYuv/zyeOihhyIiYmhoKGpqauK2226LNWvWHHd+Y2Nj9PX1xU9/+tPhY3/1V38VCxYsiM2bN+f1mL29vVFZWRk9PT1RUVFRyHIB8jKRc8YcBYrReMyZ6YWcPDAwELt37461a9cOH5s2bVrU19dHR0fHqNd0dHREU1PTiGMNDQ3xzDPPnPBx+vv7o7+/f/jrnp6eiHjnFwBgPLw7Xwr8u3vBzFGgWI3HHC0oVI8cORKDg4NRVVU14nhVVVXs379/1Gu6urpGPb+rq+uEj9PS0hL33HPPccdramoKWS5Awf77v/87Kisrx+3+zVGg2J3OOVpQqE6UtWvXjnj24M0334yPfOQjcfDgwXH9A2Sy9Pb2Rk1NTRw6dKgoX5Ir9v1FFP8ei31/Ee8843jeeefFueeeO9lLOS3M0eJT7Hu0v6lvPOZoQaE6c+bMKC0tje7u7hHHu7u7o7q6etRrqqurCzo/IiKXy0UulzvueGVlZdF+cyMiKioq7G+KK/Y9Fvv+It55GX48maPj64Pwe7TY92h/U9/pnKMF3VNZWVksXLgw2tvbh48NDQ1Fe3t71NXVjXpNXV3diPMjIp577rkTng9QzMxRgPwV/NJ/U1NTrFixIhYtWhSLFy+OTZs2RV9fX6xcuTIiIpYvXx5z586NlpaWiIi4/fbb4+qrr44HHnggrrvuuti6dWv86le/ikceeeT07gRgijBHAfJTcKg2NjbG4cOHY/369dHV1RULFiyItra24R/0P3jw4IinfK+44op44okn4q677oo777wzPv7xj8czzzwTF198cd6Pmcvlorm5edSXsYqB/U19xb7HYt9fxMTu0Rw9/Yp9fxHFv0f7m/rGY48Ff44qAABMhPF91wAAAIyRUAUAIElCFQCAJAlVAACSlEyotra2xrx586K8vDxqa2tj165dJz3/xz/+cVx00UVRXl4el1xySezYsWOCVjo2hexvy5YtcdVVV8WMGTNixowZUV9f/76/HpOt0O/fu7Zu3RolJSWxdOnS8V3gaVDoHt98881YtWpVzJ49O3K5XFx44YVJ/z4tdH+bNm2KT3ziE3HmmWdGTU1NrF69Ov70pz9N0GoL84tf/CKWLFkSc+bMiZKSknjmmWfe95qdO3fGZz7zmcjlcvGxj30sHn/88XFf56kyR98zFedoRPHPUnN0JHM0D1kCtm7dmpWVlWWPPfZY9p//+Z/ZzTffnJ1zzjlZd3f3qOf/8pe/zEpLS7P77rsve+mll7K77rorO+OMM7IXX3xxgleen0L3d8MNN2Stra3Z3r17s3379mV/93d/l1VWVmb/9V//NcErz0+h+3vXa6+9ls2dOze76qqrsr/927+dmMWOUaF77O/vzxYtWpRde+212fPPP5+99tpr2c6dO7POzs4JXnl+Ct3fD3/4wyyXy2U//OEPs9deey179tlns9mzZ2erV6+e4JXnZ8eOHdm6deuyp556KouI7Omnnz7p+QcOHMjOOuusrKmpKXvppZey73znO1lpaWnW1tY2MQseA3N0pKk2R7Os+GepOTqSOZqfJEJ18eLF2apVq4a/HhwczObMmZO1tLSMev4Xv/jF7LrrrhtxrLa2Nvv7v//7cV3nWBW6vz937Nix7Oyzz85+8IMfjNcST8lY9nfs2LHsiiuuyL73ve9lK1asSHq4Zlnhe/zud7+bnX/++dnAwMBELfGUFLq/VatWZX/913894lhTU1N25ZVXjus6T4d8BuzXv/717NOf/vSIY42NjVlDQ8M4ruzUmKMnl/oczbLin6Xm6EjmaH4m/aX/gYGB2L17d9TX1w8fmzZtWtTX10dHR8eo13R0dIw4PyKioaHhhOdPprHs78+99dZb8fbbb8e55547Xsscs7Hu75vf/GbMmjUrbrzxxolY5ikZyx5/8pOfRF1dXaxatSqqqqri4osvjg0bNsTg4OBELTtvY9nfFVdcEbt37x5+WevAgQOxY8eOuPbaaydkzeNtKs2YCHM0HynP0Yjin6Xm6PHM0fwU/C9TnW5HjhyJwcHB4X+R5V1VVVWxf//+Ua/p6uoa9fyurq5xW+dYjWV/f+6OO+6IOXPmHPcNT8FY9vf888/Ho48+Gp2dnROwwlM3lj0eOHAg/v3f/z2+/OUvx44dO+LVV1+Nr371q/H2229Hc3PzRCw7b2PZ3w033BBHjhyJz372s5FlWRw7dixuvfXWuPPOOydiyePuRDOmt7c3/vjHP8aZZ545SSsbnTn6/lKeoxHFP0vN0eOZo/nN0Ul/RpWT27hxY2zdujWefvrpKC8vn+zlnLKjR4/GsmXLYsuWLTFz5szJXs64GRoailmzZsUjjzwSCxcujMbGxli3bl1s3rx5spd2WuzcuTM2bNgQDz/8cOzZsyeeeuqp2L59e9x7772TvTQ4TrHN0YgPxiw1R4lI4BnVmTNnRmlpaXR3d4843t3dHdXV1aNeU11dXdD5k2ks+3vX/fffHxs3boyf/exncemll47nMses0P395je/iddffz2WLFkyfGxoaCgiIqZPnx4vv/xyXHDBBeO76AKN5Xs4e/bsOOOMM6K0tHT42Cc/+cno6uqKgYGBKCsrG9c1F2Is+7v77rtj2bJlcdNNN0VExCWXXBJ9fX1xyy23xLp160b8O/VT0YlmTEVFRXLPpkaYoyczFeZoRPHPUnP0eOZofib9V6GsrCwWLlwY7e3tw8eGhoaivb096urqRr2mrq5uxPkREc8999wJz59MY9lfRMR9990X9957b7S1tcWiRYsmYqljUuj+LrroonjxxRejs7Nz+Pb5z38+rrnmmujs7IyampqJXH5exvI9vPLKK+PVV18d/oMjIuKVV16J2bNnJzVcI8a2v7feeuu4IfruHybv/Jz91DaVZkyEOXoiU2WORhT/LDVHj2eO5qmgt16Nk61bt2a5XC57/PHHs5deeim75ZZbsnPOOSfr6urKsizLli1blq1Zs2b4/F/+8pfZ9OnTs/vvvz/bt29f1tzcnPzHqhSyv40bN2ZlZWXZk08+mf3+978fvh09enSytnBShe7vz6X+TtUsK3yPBw8ezM4+++zsH/7hH7KXX345++lPf5rNmjUr+9a3vjVZWzipQvfX3NycnX322dm//uu/ZgcOHMj+7d/+LbvggguyL37xi5O1hZM6evRotnfv3mzv3r1ZRGQPPvhgtnfv3uy3v/1tlmVZtmbNmmzZsmXD57/7sSr/9E//lO3bty9rbW2dEh9PZY5O3TmaZcU/S81Rc3TKfjxVlmXZd77zney8887LysrKssWLF2f/8R//Mfzfrr766mzFihUjzv/Rj36UXXjhhVlZWVn26U9/Otu+ffsEr7gwhezvIx/5SBYRx92am5snfuF5KvT79/9Lfbi+q9A9vvDCC1ltbW2Wy+Wy888/P/v2t7+dHTt2bIJXnb9C9vf2229n3/jGN7ILLrggKy8vz2pqarKvfvWr2f/8z/9M/MLz8POf/3zU/6fe3dOKFSuyq6+++rhrFixYkJWVlWXnn39+9v3vf3/C110oc3TF8NdTcY5mWfHPUnN0xfDX5mh+SrKsCJ5fBgCg6Ez6z6gCAMBohCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQJKEKAECShCoAAEkSqgAAJEmoAgCQpP8DSWkwf0qxvJYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quantus\n",
    "import torch\n",
    "import torchvision\n",
    "from captum.attr import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import zennit\n",
    "index = random.randint(0, len(x_batch)-1)\n",
    "\n",
    "# Plot examplary explanations!\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 5))\n",
    "axes[0].imshow(np.moveaxis(quantus.normalise_func.denormalise(x_batch_tmp[index], mean=np.array([0.485, 0.456, 0.406]), std=np.array([0.229, 0.224, 0.225])), 0, -1), vmin=0.0, vmax=1.0)\n",
    "axes[0].title.set_text(f\"ImageNet class {y_batch_tmp[index].item()}\")\n",
    "exp = axes[1].imshow(a_batch[index].reshape(224, 224), cmap=\"seismic\") \n",
    "fig.colorbar(exp, fraction=0.03, pad=0.05); \n",
    "axes[0].axis(\"off\"); axes[1].axis(\"off\"); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warnings and information:\n",
      " (1) The AUC metric is likely to be sensitive to the choice of ground truth mask i.e., the 's_batch' input as well as if absolute values 'abs' are taken of the attributions .  \n",
      " (2) If attributions are normalised or their absolute values are taken it may destroy or skew information in the explanation and as a result, affect the overall evaluation outcome.\n",
      " (3) Make sure to validate the choices for hyperparameters of the metric (by calling .get_params of the metric instance).\n",
      " (4) For further information, see original publication: Fawcett, Tom. 'An introduction to ROC analysis' Pattern Recognition Letters Vol 27, Issue 8, (2006).\n",
      " (5) To disable these warnings set 'disable_warnings' = True when initialising the metric.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/anaconda3/envs/xai-chan/lib/python3.9/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m quantus\u001b[39m.\u001b[39;49mAUC(\n\u001b[1;32m      2\u001b[0m )(model\u001b[39m=\u001b[39;49mdownstream_task_model, \n\u001b[1;32m      3\u001b[0m    x_batch\u001b[39m=\u001b[39;49mx_batch,\n\u001b[1;32m      4\u001b[0m    y_batch\u001b[39m=\u001b[39;49my_batch,\n\u001b[1;32m      5\u001b[0m    a_batch\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      6\u001b[0m    explain_func\u001b[39m=\u001b[39;49mquantus\u001b[39m.\u001b[39;49mexplain, \n\u001b[1;32m      7\u001b[0m   explain_func_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mSaliency\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[1;32m      8\u001b[0m   device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/quantus/metrics/localisation/auc.py:206\u001b[0m, in \u001b[0;36mAUC.__call__\u001b[0;34m(self, model, x_batch, y_batch, a_batch, s_batch, channel_first, explain_func, explain_func_kwargs, model_predict_kwargs, softmax, device, batch_size, custom_batch, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    119\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    120\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    134\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m    135\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m        This implementation represents the main logic of the metric and makes the class object callable.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m        It completes instance-wise evaluation of explanations (a_batch) with respect to input data (x_batch),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39m            >> scores = metric(model=model, x_batch=x_batch, y_batch=y_batch, a_batch=a_batch_saliency}\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\n\u001b[1;32m    207\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    208\u001b[0m         x_batch\u001b[39m=\u001b[39;49mx_batch,\n\u001b[1;32m    209\u001b[0m         y_batch\u001b[39m=\u001b[39;49my_batch,\n\u001b[1;32m    210\u001b[0m         a_batch\u001b[39m=\u001b[39;49ma_batch,\n\u001b[1;32m    211\u001b[0m         s_batch\u001b[39m=\u001b[39;49ms_batch,\n\u001b[1;32m    212\u001b[0m         custom_batch\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    213\u001b[0m         channel_first\u001b[39m=\u001b[39;49mchannel_first,\n\u001b[1;32m    214\u001b[0m         explain_func\u001b[39m=\u001b[39;49mexplain_func,\n\u001b[1;32m    215\u001b[0m         explain_func_kwargs\u001b[39m=\u001b[39;49mexplain_func_kwargs,\n\u001b[1;32m    216\u001b[0m         softmax\u001b[39m=\u001b[39;49msoftmax,\n\u001b[1;32m    217\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    218\u001b[0m         model_predict_kwargs\u001b[39m=\u001b[39;49mmodel_predict_kwargs,\n\u001b[1;32m    219\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    220\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/quantus/metrics/base.py:247\u001b[0m, in \u001b[0;36mMetric.__call__\u001b[0;34m(self, model, x_batch, y_batch, a_batch, s_batch, channel_first, explain_func, explain_func_kwargs, model_predict_kwargs, softmax, device, batch_size, custom_batch, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m warn\u001b[39m.\u001b[39mdeprecation_warnings(kwargs)\n\u001b[1;32m    245\u001b[0m warn\u001b[39m.\u001b[39mcheck_kwargs(kwargs)\n\u001b[0;32m--> 247\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgeneral_preprocess(\n\u001b[1;32m    248\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    249\u001b[0m     x_batch\u001b[39m=\u001b[39;49mx_batch,\n\u001b[1;32m    250\u001b[0m     y_batch\u001b[39m=\u001b[39;49my_batch,\n\u001b[1;32m    251\u001b[0m     a_batch\u001b[39m=\u001b[39;49ma_batch,\n\u001b[1;32m    252\u001b[0m     s_batch\u001b[39m=\u001b[39;49ms_batch,\n\u001b[1;32m    253\u001b[0m     channel_first\u001b[39m=\u001b[39;49mchannel_first,\n\u001b[1;32m    254\u001b[0m     explain_func\u001b[39m=\u001b[39;49mexplain_func,\n\u001b[1;32m    255\u001b[0m     explain_func_kwargs\u001b[39m=\u001b[39;49mexplain_func_kwargs,\n\u001b[1;32m    256\u001b[0m     model_predict_kwargs\u001b[39m=\u001b[39;49mmodel_predict_kwargs,\n\u001b[1;32m    257\u001b[0m     softmax\u001b[39m=\u001b[39;49msoftmax,\n\u001b[1;32m    258\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    259\u001b[0m     custom_batch\u001b[39m=\u001b[39;49mcustom_batch,\n\u001b[1;32m    260\u001b[0m )\n\u001b[1;32m    262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_scores \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m x_batch]\n\u001b[1;32m    264\u001b[0m \u001b[39m# Evaluate with instance given the metric.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/quantus/metrics/base.py:427\u001b[0m, in \u001b[0;36mMetric.general_preprocess\u001b[0;34m(self, model, x_batch, y_batch, a_batch, s_batch, channel_first, explain_func, explain_func_kwargs, model_predict_kwargs, softmax, device, custom_batch)\u001b[0m\n\u001b[1;32m    424\u001b[0m     asserts\u001b[39m.\u001b[39massert_explain_func(explain_func\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplain_func)\n\u001b[1;32m    426\u001b[0m     \u001b[39m# Generate explanations.\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m     a_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexplain_func(\n\u001b[1;32m    428\u001b[0m         model\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mget_model(),\n\u001b[1;32m    429\u001b[0m         inputs\u001b[39m=\u001b[39;49mx_batch,\n\u001b[1;32m    430\u001b[0m         targets\u001b[39m=\u001b[39;49my_batch,\n\u001b[1;32m    431\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexplain_func_kwargs,\n\u001b[1;32m    432\u001b[0m     )\n\u001b[1;32m    434\u001b[0m \u001b[39m# Expand attributions to input dimensionality.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m a_batch \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mexpand_attribution_channel(a_batch, x_batch)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/quantus/functions/explanation_func.py:126\u001b[0m, in \u001b[0;36mexplain\u001b[0;34m(model, inputs, targets, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m __EXTRAS__:\n\u001b[1;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExplanation library not found. Please install Captum or Zennit for torch>=1.2 models \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand tf-explain for TensorFlow>=2.0.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 126\u001b[0m explanation \u001b[39m=\u001b[39m get_explanation(model, inputs, targets, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    128\u001b[0m \u001b[39mreturn\u001b[39;00m explanation\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/quantus/functions/explanation_func.py:178\u001b[0m, in \u001b[0;36mget_explanation\u001b[0;34m(model, inputs, targets, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m util\u001b[39m.\u001b[39mfind_spec(\u001b[39m\"\u001b[39m\u001b[39mcaptum\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m util\u001b[39m.\u001b[39mfind_spec(\u001b[39m\"\u001b[39m\u001b[39mzennit\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    177\u001b[0m     \u001b[39mif\u001b[39;00m xai_lib \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcaptum\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[39mreturn\u001b[39;00m generate_captum_explanation(model, inputs, targets, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m xai_lib \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzennit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    180\u001b[0m         \u001b[39mreturn\u001b[39;00m generate_zennit_explanation(model, inputs, targets, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/quantus/functions/explanation_func.py:576\u001b[0m, in \u001b[0;36mgenerate_captum_explanation\u001b[0;34m(model, inputs, targets, device, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39min\u001b[39;00m [\n\u001b[1;32m    565\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mInputXGradient\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    566\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSaliency\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mLRP\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    573\u001b[0m ]:\n\u001b[1;32m    574\u001b[0m     attr_func \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(method)\n\u001b[1;32m    575\u001b[0m     explanation \u001b[39m=\u001b[39m f_reduce_axes(\n\u001b[0;32m--> 576\u001b[0m         attr_func(model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mxai_lib_kwargs)\u001b[39m.\u001b[39;49mattribute(inputs\u001b[39m=\u001b[39;49minputs, target\u001b[39m=\u001b[39;49mtargets)\n\u001b[1;32m    577\u001b[0m     )\n\u001b[1;32m    579\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGradient\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    580\u001b[0m     explanation \u001b[39m=\u001b[39m f_reduce_axes(\n\u001b[1;32m    581\u001b[0m         Saliency(model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mxai_lib_kwargs)\u001b[39m.\u001b[39mattribute(\n\u001b[1;32m    582\u001b[0m             inputs\u001b[39m=\u001b[39minputs, target\u001b[39m=\u001b[39mtargets, \u001b[39mabs\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    583\u001b[0m         )\n\u001b[1;32m    584\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/captum/attr/_core/saliency.py:130\u001b[0m, in \u001b[0;36mSaliency.attribute\u001b[0;34m(self, inputs, target, abs, additional_forward_args)\u001b[0m\n\u001b[1;32m    126\u001b[0m gradient_mask \u001b[39m=\u001b[39m apply_gradient_requirements(inputs)\n\u001b[1;32m    128\u001b[0m \u001b[39m# No need to format additional_forward_args here.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m# They are being formated in the `_run_forward` function in `common.py`\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m gradients \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_func(\n\u001b[1;32m    131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_func, inputs, target, additional_forward_args\n\u001b[1;32m    132\u001b[0m )\n\u001b[1;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mabs\u001b[39m:\n\u001b[1;32m    134\u001b[0m     attributions \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(torch\u001b[39m.\u001b[39mabs(gradient) \u001b[39mfor\u001b[39;00m gradient \u001b[39min\u001b[39;00m gradients)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/captum/_utils/gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[39m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     outputs \u001b[39m=\u001b[39m _run_forward(forward_fn, inputs, target_ind, additional_forward_args)\n\u001b[1;32m    113\u001b[0m     \u001b[39massert\u001b[39;00m outputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTarget not provided when necessary, cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m take gradient with respect to multiple outputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[39m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/captum/_utils/common.py:482\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    479\u001b[0m inputs \u001b[39m=\u001b[39m _format_inputs(inputs)\n\u001b[1;32m    480\u001b[0m additional_forward_args \u001b[39m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[0;32m--> 482\u001b[0m output \u001b[39m=\u001b[39m forward_func(\n\u001b[1;32m    483\u001b[0m     \u001b[39m*\u001b[39;49m(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49madditional_forward_args)\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;49;00m additional_forward_args \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    485\u001b[0m     \u001b[39melse\u001b[39;49;00m inputs\n\u001b[1;32m    486\u001b[0m )\n\u001b[1;32m    487\u001b[0m \u001b[39mreturn\u001b[39;00m _select_targets(output, target)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/31171109-donotdelete/xai-chan/utils/models.py:60\u001b[0m, in \u001b[0;36mResNet_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_sigmoid_head:\n\u001b[0;32m---> 60\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msig(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x))\n\u001b[1;32m     61\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torchvision/models/resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[39m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    269\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "quantus.AUC(\n",
    ")(model=downstream_task_model, \n",
    "   x_batch=x_batch.cuda(),\n",
    "   y_batch=y_batch.cuda(),\n",
    "   a_batch=None,\n",
    "   explain_func=quantus.explain, \n",
    "  explain_func_kwargs={\"method\": \"Saliency\"},\n",
    "  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantus.AUC(\n",
    ")(model=model, \n",
    "   x_batch=x_batch,\n",
    "   y_batch=y_batch,\n",
    "   a_batch=None,\n",
    "   s_batch=s_batch,\n",
    "   explain_func=quantus.explain, \n",
    "  explain_func_kwargs={\"method\": \"Saliency\"},\n",
    "  device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-chan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
