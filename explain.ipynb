{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torch\n",
    "# Append custom paths to sys.path for importing custom modules\n",
    "sys.path.append(os.path.dirname(\"/home/student/Desktop/31171109-donotdelete/xai-chan/utils\"))\n",
    "from utils.models import ResNet_Model\n",
    "from utils.transform import resize_transform\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/student/anaconda3/envs/xai-chan/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet_Model(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.8, inplace=False)\n",
       "      (1): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "version = 50\n",
    "downstream_task_model = ResNet_Model(version=version).to(device)\n",
    "weights_path = \"/home/student/Desktop/31171109-donotdelete/xai-chan/result/imagenet/_Fold_2_5_400X_BreakHis_FT_60_resnet50_imagenet_/_37_96.07250755287009_95.06917631917632_0.9614846110343933.pth\"  # TODO: Provide the model path\n",
    "downstream_task_model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "downstream_task_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6824, 0.6471, 0.6000,  ..., 0.6980, 0.6980, 0.7020],\n",
      "          [0.6941, 0.6510, 0.5961,  ..., 0.6784, 0.6941, 0.6902],\n",
      "          [0.6941, 0.6510, 0.5882,  ..., 0.6588, 0.6863, 0.6824],\n",
      "          ...,\n",
      "          [0.6510, 0.6588, 0.6627,  ..., 0.6706, 0.6706, 0.6588],\n",
      "          [0.6353, 0.6510, 0.6549,  ..., 0.6706, 0.6627, 0.6510],\n",
      "          [0.6235, 0.6353, 0.6510,  ..., 0.6431, 0.6431, 0.6392]],\n",
      "\n",
      "         [[0.6980, 0.6588, 0.6000,  ..., 0.7020, 0.7020, 0.7098],\n",
      "          [0.7137, 0.6627, 0.5922,  ..., 0.6824, 0.6941, 0.6980],\n",
      "          [0.7176, 0.6627, 0.5843,  ..., 0.6549, 0.6824, 0.6941],\n",
      "          ...,\n",
      "          [0.6196, 0.6196, 0.6235,  ..., 0.6549, 0.6549, 0.6510],\n",
      "          [0.6039, 0.6118, 0.6157,  ..., 0.6549, 0.6510, 0.6431],\n",
      "          [0.5922, 0.5961, 0.6118,  ..., 0.6275, 0.6353, 0.6392]],\n",
      "\n",
      "         [[0.7373, 0.7176, 0.6902,  ..., 0.7176, 0.7176, 0.7255],\n",
      "          [0.7412, 0.7176, 0.6784,  ..., 0.7059, 0.7176, 0.7137],\n",
      "          [0.7412, 0.7137, 0.6706,  ..., 0.6941, 0.7137, 0.7059],\n",
      "          ...,\n",
      "          [0.6902, 0.7059, 0.7137,  ..., 0.7020, 0.6980, 0.6980],\n",
      "          [0.6784, 0.6980, 0.7098,  ..., 0.7098, 0.7059, 0.6941],\n",
      "          [0.6706, 0.6863, 0.7098,  ..., 0.6824, 0.6902, 0.6902]]]],\n",
      "       device='cuda:0')\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Prepare input\n",
    "# image_path = \"/home/student/Desktop/31171109-donotdelete/xai-chan/dataset/benign/SOB/adenosis/SOB_B_A_14-22549AB/100X/SOB_B_A-14-22549AB-100-001.png\"  # TODO: Provide the image path\n",
    "# image_path = \"/home/student/Desktop/31171109-donotdelete/xai-chan/dataset/malignant/SOB/mucinous_carcinoma/SOB_M_MC_14-10147/100X/SOB_M_MC-14-10147-100-001.png\"\n",
    "image_path =\"/home/student/Desktop/31171109-donotdelete/xai-chan/explanation/val_10/SOB_B_F_14-21998EF/400X/SOB_B_F-14-21998EF-400-001.png\"\n",
    "input_rgb = Image.open(image_path)\n",
    "width, height = input_rgb.size\n",
    "# print(f\"Width: {width}, Height: {height}\")\n",
    "input_tensor = resize_transform(np.array(input_rgb)).unsqueeze(0).to(device)\n",
    "print(input_tensor)\n",
    "outputs = downstream_task_model(input_tensor)\n",
    "target_category = (outputs > 0.2).int().item()\n",
    "print(target_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 3.891564119840041e-06\n"
     ]
    }
   ],
   "source": [
    "from zennit.image import imgify, imsave  # For creating visualizations\n",
    "from zennit.torchvision import ResNetCanonizer  # For ResNet-specific canonization\n",
    "from zennit.composites import EpsilonPlusFlat  # For the composite function in LRP\n",
    "from zennit.attribution import Gradient  # For attributing using gradients\n",
    "from IPython.display import display\n",
    "# Make sure your model is in evaluation mode\n",
    "downstream_task_model.eval()\n",
    "\n",
    "# Use the ResNet-specific canonizer\n",
    "canonizer = ResNetCanonizer()\n",
    "\n",
    "# Create a composite, specifying the canonizers\n",
    "composite = EpsilonPlusFlat(canonizers=[canonizer])\n",
    "\n",
    "target = torch.tensor([[1.0]]).to(device)\n",
    "\n",
    "# Create the attributor, specifying model and composite\n",
    "with Gradient(model=downstream_task_model, composite=composite) as attributor:\n",
    "    # Compute the model output and attribution\n",
    "    output, attribution = attributor(input_tensor, target)\n",
    "\n",
    "print(f'Prediction: {output.item()}')  # Adapted for a binary classification output\n",
    "\n",
    "# Sum over the channels\n",
    "relevance = attribution.sum(1).cpu()\n",
    "\n",
    "# Create an image of the visualized attribution\n",
    "img = imgify(relevance, symmetric=True, cmap='coldnhot')\n",
    "\n",
    "\n",
    "\n",
    "# Convert the image to RGB mode and then display it\n",
    "img.convert('RGB').show()\n",
    "\n",
    "# Show the image\n",
    "# directly save the visualized attribution\n",
    "imsave('/home/student/Desktop/31171109-donotdelete/xai-chan/explanation/explanation/SOB_B_F-14-21998EF-400-001-heatmap.png', relevance, symmetric=True, cmap='coldnhot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "from zennit.attribution import Gradient, SmoothGrad\n",
    "from zennit.core import Stabilizer\n",
    "from zennit.composites import EpsilonGammaBox, EpsilonPlusFlat\n",
    "from zennit.composites import SpecialFirstLayerMapComposite, NameMapComposite\n",
    "\n",
    "from zennit.rules import Epsilon, ZPlus, ZBox, Norm, Pass, Flat\n",
    "from zennit.types import Convolution, Activation, AvgPool, Linear as AnyLinear\n",
    "from zennit.types import BatchNorm, MaxPool\n",
    "from zennit.torchvision import VGGCanonizer, ResNetCanonizer\n",
    "# Given that you're working with images in [0, 1] range\n",
    "low, high = torch.tensor([[[[[0.]]] * 3], [[[[1.]]] * 3]])\n",
    "\n",
    "composite = SpecialFirstLayerMapComposite(\n",
    "    layer_map=[\n",
    "        (nn.ReLU, Pass()),  # if your model uses ReLU activations\n",
    "        (nn.AvgPool2d, Norm()),  # Normalize relevance for any Average Pooling layers\n",
    "        (nn.Conv2d, ZPlus()),  # Any convolutional layer\n",
    "        (nn.Linear, Epsilon(epsilon=1e-6)),  # Linear layers\n",
    "        (nn.BatchNorm2d, Pass()),  # Ignore BatchNorm layers\n",
    "    ],\n",
    "    first_map=[\n",
    "        (AnyLinear, ZBox(low, high))\n",
    "    ]\n",
    ")\n",
    "target = torch.tensor([[target_category]]).float().to(device)\n",
    "# directly save the visualized attribution\n",
    "imsave('attrib-1.png', relevance, symmetric=True, cmap='coldnhot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "from zennit.image import imgify, imsave  # For creating visualizations\n",
    "from zennit.torchvision import ResNetCanonizer  # For ResNet-specific canonization\n",
    "from zennit.composites import EpsilonPlusFlat  # For the composite function in LRP\n",
    "from zennit.attribution import Gradient  # For attributing using gradients\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "def compute_heatmap(img_tensor, model, target):\n",
    "    canonizer = ResNetCanonizer()\n",
    "    composite = EpsilonPlusFlat(canonizers=[canonizer])\n",
    "    \n",
    "    with Gradient(model=model, composite=composite) as attributor:\n",
    "        output, attribution = attributor(img_tensor, target)\n",
    "    \n",
    "    # Sum over the channels\n",
    "    relevance = attribution.sum(1).cpu()\n",
    "    return relevance\n",
    "\n",
    "# Function to generate heatmaps for all images in a directory\n",
    "def generate_heatmaps(directory, model):\n",
    "    model.eval()\n",
    "    target = torch.tensor([[1.0]]).to(device)\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_tensor = resize_transform(img).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "            relevance = compute_heatmap(img_tensor, model, target)\n",
    "            \n",
    "            # Save the heatmap\n",
    "            heatmap_filename = f\"{filename.split('.')[0]}_gradient.png\"  # Removing the original extension and appending the method name\n",
    "            heatmap_path = os.path.join(directory, heatmap_filename)\n",
    "            imsave(heatmap_path, relevance, symmetric=True, cmap='coldnhot')\n",
    "\n",
    "# Execute the function\n",
    "generate_heatmaps(\"/path/to/image/directory\", downstream_task_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-chan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
